{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "home = str(Path.home()) # all other paths are relative to this path. change to something else if this is not the case on your system\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# make sure your run the cell above before running this\n",
    "import Lab4_helper\n",
    "import Lab5_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment should be relatively straightforward. I'm going to reuse the code I wrote in lab 4 to create a decision tree and then modify the code I wrote in lab 5 to select a random subset of the features during bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset from Lab 4\n",
    "Since the dataset from lab 5 doesn't have many features but lab 4 does, random forest will have more dramatic results, since the whole thing that's special about random forest is taking a random subset of the features. If we don't, it's just bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the data in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "diabetes_df = pd.read_csv(\n",
    "    f\"./diabetes_indicators.csv\"\n",
    ")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same preprocessing we used in lab4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex   Age  Education  Income  Fruits  Veggies  Smoker  HighChol   BMI\n",
       "0    0.0   9.0        4.0     3.0     0.0      1.0     1.0       1.0  40.0\n",
       "1    0.0   7.0        6.0     1.0     0.0      0.0     1.0       0.0  25.0\n",
       "2    0.0   9.0        4.0     8.0     1.0      0.0     0.0       1.0  28.0\n",
       "3    0.0  11.0        3.0     6.0     1.0      1.0     0.0       0.0  27.0\n",
       "4    0.0  11.0        5.0     4.0     1.0      1.0     0.0       1.0  24.0\n",
       "..   ...   ...        ...     ...     ...      ...     ...       ...   ...\n",
       "995  0.0   2.0        6.0     8.0     1.0      0.0     0.0       0.0  31.0\n",
       "996  0.0  10.0        5.0     8.0     0.0      1.0     0.0       0.0  21.0\n",
       "997  1.0   7.0        4.0     1.0     0.0      0.0     0.0       1.0  31.0\n",
       "998  0.0   5.0        4.0     8.0     1.0      1.0     0.0       0.0  37.0\n",
       "999  1.0  11.0        4.0     7.0     0.0      1.0     1.0       0.0  28.0\n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['Sex','Age','Education','Income','Fruits','Veggies','Smoker', \"HighChol\", \"BMI\"]\n",
    "dia_X = diabetes_df.loc[:,features][:1000]\n",
    "dia_X = dia_X.dropna()\n",
    "dia_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "      ... \n",
       "995    0.0\n",
       "996    0.0\n",
       "997    0.0\n",
       "998    0.0\n",
       "999    0.0\n",
       "Name: Diabetes_012, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dia_t = diabetes_df.loc[dia_X.index,'Diabetes_012']\n",
    "dia_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use my decision tree from lab4 straight out of the box, no modifacation needed. I do want to compare how it'll do against the other methods, and show that it works, so I'll run it on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c45': 0.6431422505307854}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "default = 0\n",
    "results = {}\n",
    "dia_X_train, dia_X_test, dia_t_train, dia_t_test = train_test_split(dia_X, dia_t, test_size=0.3, random_state = 0)\n",
    "c45_tree = Lab4_helper.make_tree2(dia_X_train, dia_t_train)\n",
    "rules_c45 = Lab4_helper.generate_rules(c45_tree)\n",
    "y_c45 = dia_X_test.apply(lambda x: Lab4_helper.make_prediction(rules_c45,x,default),axis=1)\n",
    "c45_f1 = f1_score(dia_t_test, y_c45, average=\"weighted\")\n",
    "results[\"c45\"] = c45_f1\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the bagging code but we take a random subset of the features for every bag. After doing some reading, it looks like it's best to use $\\sqrt{n}$ features for every learner for classifacation problems, where n is the number of features in total. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have the modify the code to use our scratch random forest instead of ouf the scikit learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def make_tree_rf(X,y,min_split_count=5, prevFeature = \"\", prevPrevFeature = \"\"):\n",
    "    tree = {}\n",
    "    differentYVals = y.unique()\n",
    "    defaultAns = y.value_counts().sort_values(ascending=False).index[0]\n",
    "\n",
    "    #selecting a subset of the features\n",
    "    numFeatures = int(np.round_(np.sqrt(X.shape[1])))\n",
    "    X = X.sample(n = numFeatures, axis=\"columns\")\n",
    "    \n",
    "    if(differentYVals.size) == 1:\n",
    "        return defaultAns\n",
    "    if(X.shape[0] < min_split_count):\n",
    "        return defaultAns\n",
    "    if(X.shape[1] == 0):\n",
    "        return defaultAns\n",
    "    if(X.drop_duplicates().shape[0] == 1):\n",
    "        return defaultAns\n",
    "    #then we're in the recursive case\n",
    "    \n",
    "    \n",
    "    #pick the field with the highest IG\n",
    "    bestFeature, rig = Lab4_helper.select_split2(X, y)\n",
    "    if rig <= 0.001:\n",
    "        return defaultAns\n",
    "    \n",
    "    #replacing the continous column with its split counterpart\n",
    "    bestFeatureName = bestFeature.name\n",
    "    originalColumnName = bestFeatureName.split(\"<\")[0]\n",
    "    X = X.drop(columns=[originalColumnName])\n",
    "    X[bestFeatureName] = bestFeature\n",
    "\n",
    "    #setting up tree\n",
    "    tree[bestFeatureName] = {}\n",
    "    possibleFeatureValues = [True, False]\n",
    "    \n",
    "    #recursing\n",
    "    for value in possibleFeatureValues:\n",
    "        XAtVal = X.loc[X[bestFeatureName] == value]\n",
    "        YAtVal = y.loc[X[bestFeatureName] == value]     \n",
    "        RestOfX = XAtVal.drop(columns=bestFeatureName)\n",
    "        tree[bestFeatureName][str(value).capitalize()] = make_tree_rf(RestOfX, YAtVal, prevFeature=bestFeatureName, prevPrevFeature=prevFeature)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "def make_trees(x, t, ntrees):\n",
    "    trees = []\n",
    "    for _ in range(ntrees):\n",
    "        #grabbing a random resample of the rows\n",
    "        x_i, y_i = resample(x, t)\n",
    "        tree = make_tree_rf(x_i, y_i)\n",
    "        trees.append(tree)\n",
    "\n",
    "    return trees\n",
    "\n",
    "def make_rules(trees):\n",
    "    rules = []\n",
    "    for tree in trees:\n",
    "        rule = Lab4_helper.generate_rules(tree)\n",
    "        rules.append(rule)\n",
    "    \n",
    "    return rules\n",
    "\n",
    "def make_pred_from_rules(x, rules, default = 0):\n",
    "    predictions = pd.DataFrame()\n",
    "    for rule in rules:\n",
    "        #making the prediction from a single truee\n",
    "        pred = x.apply(lambda x: Lab4_helper.make_prediction(rule,x,default),axis=1)\n",
    "        #adding it to our dataframe of predictions\n",
    "        predictions = pd.concat([predictions, pred], axis = 1)\n",
    "\n",
    "    #we want the prediction to be the most populator prediction from our subset of predictions\n",
    "    aggregate_prediction = predictions.mode(axis=1)\n",
    "    return aggregate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def run_test(X, t, results, type, alg, ntrials, ntrees):\n",
    "    scores = []\n",
    "    for trial in range(ntrials):\n",
    "        #splitting\n",
    "        X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3,random_state=trial)\n",
    "        #performing algorithm\n",
    "        y = None\n",
    "        if alg == \"random_forest\" and type == \"classifier\":\n",
    "            trees = make_trees(X_train, t_train, ntrees=ntrees)\n",
    "            rules = make_rules(trees)\n",
    "            y = make_pred_from_rules(X_test, rules, default=default)\n",
    "        if alg == \"bagging\":\n",
    "            trees = Lab5_helper.make_trees(X_train, t_train,ntrees=ntrees, type=type)\n",
    "            y = Lab5_helper.make_prediction(trees, X_test, type=type)\n",
    "        if alg == \"sk_random_forest\" and type == \"classifier\":\n",
    "            model = RandomForestClassifier(n_estimators=ntrees, min_samples_split=5, random_state=trial, criterion=\"entropy\").fit(X_train, t_train)\n",
    "            y = model.predict(X_test)\n",
    "        if alg == \"boosting\" and type == \"classifier\":\n",
    "            boostingClassifier = GradientBoostingClassifier(n_estimators=ntrees).fit(X_train, t_train)\n",
    "            y = boostingClassifier.predict(X_test)\n",
    "        #calculating performance\n",
    "        if type == \"classifier\":\n",
    "            scores.append(f1_score(y, t_test, average=\"weighted\"))\n",
    "        elif type == \"regressor\":\n",
    "            scores.append(np.sqrt(((y-t_test)**2).sum()/len(t_test)))\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    results[alg] = average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': 0.8569341877380964}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_results = {}\n",
    "run_test(X=dia_X, t= dia_t, results=classification_results, type=\"classifier\", alg=\"random_forest\", ntrials=10, ntrees=5)\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': 0.8569341877380964, 'bagging': 0.7374099015470598}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_test(X=dia_X, t= dia_t, results=classification_results, type=\"classifier\", alg=\"bagging\", ntrials=10, ntrees=5)\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': 0.8569341877380964,\n",
       " 'bagging': 0.7374099015470598,\n",
       " 'sk_random_forest': 0.7977920649619576}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_test(X=dia_X, t= dia_t, results=classification_results, type=\"classifier\", alg=\"sk_random_forest\", ntrials=10, ntrees=25)\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': 0.8569341877380964,\n",
       " 'bagging': 0.7374099015470598,\n",
       " 'sk_random_forest': 0.7977920649619576,\n",
       " 'boosting': 0.819052444520835}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_test(X=dia_X, t= dia_t, results=classification_results, type=\"classifier\", alg=\"boosting\", ntrials=10, ntrees=25)\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to built in implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay sweet, that's a noticable improvement from a single tree!\n",
    "Lets compare it to bagging and boosting.\n",
    "The following code will be pretty much straight lab 5 code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really cool! The random forest algorithm did better than than built-in boosting algorithm did!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the algorithms to other datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use a dataset that contains the chemical properties of various red wines and their numerical rating of \"quality\". I'm going to try to do a regression between those properties and the quality. I obtained the dataset from https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset in and preprocessing\n",
    "displaying the raw dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./winequality-red.csv\", delimiter=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "displaying the preprocessed X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.528194</td>\n",
       "      <td>0.961576</td>\n",
       "      <td>-1.391037</td>\n",
       "      <td>-0.453077</td>\n",
       "      <td>-0.243630</td>\n",
       "      <td>-0.466047</td>\n",
       "      <td>-0.379014</td>\n",
       "      <td>0.558100</td>\n",
       "      <td>1.288240</td>\n",
       "      <td>-0.579025</td>\n",
       "      <td>-0.959946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.298454</td>\n",
       "      <td>1.966827</td>\n",
       "      <td>-1.391037</td>\n",
       "      <td>0.043403</td>\n",
       "      <td>0.223805</td>\n",
       "      <td>0.872365</td>\n",
       "      <td>0.624168</td>\n",
       "      <td>0.028252</td>\n",
       "      <td>-0.719708</td>\n",
       "      <td>0.128910</td>\n",
       "      <td>-0.584594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.298454</td>\n",
       "      <td>1.296660</td>\n",
       "      <td>-1.185699</td>\n",
       "      <td>-0.169374</td>\n",
       "      <td>0.096323</td>\n",
       "      <td>-0.083643</td>\n",
       "      <td>0.228975</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>-0.331073</td>\n",
       "      <td>-0.048074</td>\n",
       "      <td>-0.584594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.654339</td>\n",
       "      <td>-1.384011</td>\n",
       "      <td>1.483689</td>\n",
       "      <td>-0.453077</td>\n",
       "      <td>-0.264878</td>\n",
       "      <td>0.107558</td>\n",
       "      <td>0.411372</td>\n",
       "      <td>0.664069</td>\n",
       "      <td>-0.978798</td>\n",
       "      <td>-0.461036</td>\n",
       "      <td>-0.584594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.528194</td>\n",
       "      <td>0.961576</td>\n",
       "      <td>-1.391037</td>\n",
       "      <td>-0.453077</td>\n",
       "      <td>-0.243630</td>\n",
       "      <td>-0.466047</td>\n",
       "      <td>-0.379014</td>\n",
       "      <td>0.558100</td>\n",
       "      <td>1.288240</td>\n",
       "      <td>-0.579025</td>\n",
       "      <td>-0.959946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0      -0.528194          0.961576    -1.391037       -0.453077  -0.243630   \n",
       "1      -0.298454          1.966827    -1.391037        0.043403   0.223805   \n",
       "2      -0.298454          1.296660    -1.185699       -0.169374   0.096323   \n",
       "3       1.654339         -1.384011     1.483689       -0.453077  -0.264878   \n",
       "4      -0.528194          0.961576    -1.391037       -0.453077  -0.243630   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0            -0.466047             -0.379014  0.558100  1.288240  -0.579025   \n",
       "1             0.872365              0.624168  0.028252 -0.719708   0.128910   \n",
       "2            -0.083643              0.228975  0.134222 -0.331073  -0.048074   \n",
       "3             0.107558              0.411372  0.664069 -0.978798  -0.461036   \n",
       "4            -0.466047             -0.379014  0.558100  1.288240  -0.579025   \n",
       "\n",
       "    alcohol  \n",
       "0 -0.959946  \n",
       "1 -0.584594  \n",
       "2 -0.584594  \n",
       "3 -0.584594  \n",
       "4 -0.959946  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"quality\"])\n",
    "t = df[\"quality\"]\n",
    "X = X.apply(lambda col: (col - col.mean()) / col.std())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying random forest\n",
    "\n",
    "Because this is a regression problem, I'll be using 1/3 of the features for each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': 0.6089917169428827}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_results = {}\n",
    "ntrials = 10\n",
    "ntrees = 50\n",
    "RMSEs = []\n",
    "default = 0\n",
    "for trial in range(ntrials):\n",
    "    X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3,random_state=trial)\n",
    "    trees = Lab5_helper.make_trees(X_train,t_train,ntrees=ntrees, random_forest=True)\n",
    "    y = Lab5_helper.make_prediction(trees,X_test)\n",
    "    RMSEs.append(np.sqrt(((y-t_test)**2).sum()/len(t_test)))\n",
    "average_RMSE = sum(RMSEs) / len(RMSEs)\n",
    "wine_results[\"random_forest\"] = average_RMSE\n",
    "wine_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': 0.6089917169428827, 'bagging': 0.5895205271926941}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSEs = []\n",
    "for trial in range(ntrials):\n",
    "    X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3,random_state=trial)\n",
    "    trees = Lab5_helper.make_trees(X_train,t_train,ntrees=ntrees)\n",
    "    y = Lab5_helper.make_prediction(trees,X_test)\n",
    "    RMSEs.append(np.sqrt(((y-t_test)**2).sum()/len(t_test)))\n",
    "average_RMSE = sum(RMSEs) / len(RMSEs)\n",
    "wine_results[\"bagging\"] = average_RMSE\n",
    "wine_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': 0.6089917169428827,\n",
       " 'bagging': 0.5895205271926941,\n",
       " 'boosting': 0.6962058795294425}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSEs = []\n",
    "for trial in range(ntrials):\n",
    "    X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3,random_state=trial)\n",
    "    X_train2, X_val, t_train2, t_val = train_test_split(X_train, t_train, test_size=0.3,random_state=trial)\n",
    "    trees,train_RMSEs,val_RMSEs = Lab5_helper.make_trees_boost(X_train2, X_val, t_train2, t_val, max_ntrees=100)\n",
    "    trees = Lab5_helper.cut_trees(trees,val_RMSEs)\n",
    "    y = Lab5_helper.make_prediction_boost(trees,X_test)\n",
    "    RMSEs.append(np.sqrt(((y-t_test)**2).sum()/len(t_test)))\n",
    "average_RMSE = sum(RMSEs) / len(RMSEs)\n",
    "wine_results[\"boosting\"] = average_RMSE\n",
    "wine_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, random forest performed slightly worse than bagging alone, but both bagging methods perfomed better than boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Gain of a Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Gain at a Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Impurity\n",
    "The Gini Impurity score at node $n$ is defined as the probability of picking two different classes if you picked randomly from all the samples at node n. It ranges from 0 to 1 and the higher it is, the more impure the data and the lower it is, the more pure the data. It's mathematically described as$$g(n) = 1- \\sum_{i=1}^{j}(P_i)^2$$\n",
    "where:\n",
    "\n",
    "$n$ is the current node (split in the dataset based on the value of some feature)\n",
    "\n",
    "$j$ is the number of distinct classes,\n",
    "\n",
    "$P_i$ is what portion the $i$-th class is of all the classes (the probaiblity of selecting the $i$-th class at random)\n",
    "\n",
    "\n",
    "We can implement it with this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(x):\n",
    "    counts = x.value_counts()\n",
    "    fracs = counts / len(x)\n",
    "    ans = 1 - (fracs ** 2).sum()\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with a \"impure\" dataset A and a \"pure\" dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impurity  of A is 0.7901234567901234\n",
      "Impurity of B is 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "A = pd.Series([1,2, 2, 3, 4, 4, 1, 5, 5])\n",
    "B = pd.Series([0, 1, 1, 1, 1, 0, 1, 1, 0])\n",
    "\n",
    "print(\"Impurity  of A is\", gini(A))\n",
    "print(\"Impurity of B is\", gini(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Gini Impurity Gain\n",
    "We're interested in average decrease in gini impurity at the current node -- aka average increase in purity. That is, the difference between the gini impurity at $n$ and the weighted sum of the gini impurity of its two children. The weight of each child is what proportion of the samples at $n$ are included in the child. Mathematically this is\n",
    "$$gg(n) = g(n) - \\sum_{i = 1}^{c} \\frac{s_i}{s_n}g(c_i)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$n$ is the current node\n",
    "\n",
    "$gg(n)$ is the mean gini impurity decrease at $n$\n",
    "\n",
    "$c$ is the number of children\n",
    "\n",
    "$s_i$ is the number of samples included in the $i$-th child\n",
    "\n",
    "$s_n$ is the number of samples at $n$\n",
    "\n",
    "$g(c_i)$ is the gini impurity of the $i$-th child node\n",
    "\n",
    "we can implement it with this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, t, tree):\n",
    "    feature_name, threshold = list(tree.keys())[0].split(\"<\")\n",
    "    threshold = float(threshold)\n",
    "\n",
    "    #Split the data\n",
    "    x_l = x[x[feature_name] < threshold]\n",
    "    x_r = x[x[feature_name] >= threshold]\n",
    "    t_l = t[x[feature_name] < threshold]\n",
    "    t_r = t[x[feature_name] >= threshold]\n",
    "\n",
    "    return x_l, x_r, t_l, t_r\n",
    "\n",
    "def gid(x, t, tree):\n",
    "    #split the data by the metric in the tree. The node n is the head node of the tree. \n",
    "    #Grab the metric in question\n",
    "    x_l, x_r, t_l, t_r  = split_data(x, t, tree)\n",
    "    \n",
    "    #calculate gid\n",
    "    p_l = len(x_l) / len(x)\n",
    "    p_r = len(x_r) / len(x)\n",
    "\n",
    "    gini_n = gini(t)\n",
    "    gini_l = gini(t_l)\n",
    "    gini_r = gini(t_r)\n",
    "\n",
    "    ans = gini_n - (p_l * gini_l + p_r * gini_r)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function on a table that can be neatly divided in two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"isHot\": [0, 0, 0, 1, 1, 1], \"shouldTouch\": [1, 1, 1, 0, 0, 0,]}\n",
    "test_df = pd.DataFrame(data)\n",
    "tree = {\n",
    "    \"isHot<0.5\": {\"False\": 1,\n",
    "                  \"True\": 0}\n",
    "}\n",
    "test_x = test_df.drop(columns=[\"shouldTouch\"])\n",
    "test_t = test_df.drop(columns=[\"isHot\"])\n",
    "gid(test_x, test_t, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense! As the impurity at the start is 0.5, and the purity of each of the split tables is 0, so the weighted decrease in impurity is 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on Lab 4 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015036706311076897"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gid(dia_X_test, dia_t_test, c45_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does that seem reasonable? I have no idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance from Gini Impurity Decrease\n",
    "For every tree, for every node, we find the Gini impurity decrease and then weight it by the proportion of the  number of samples at the node to the number of samples in total. We take that value and average it over each feature. This is our feature importance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for recursing through tree and calculating gid at every node:\n",
    "def gini_importance_from_tree(x, t, tree, n_samples, feature_results):\n",
    "    if len(x) == 0:\n",
    "        return \n",
    "    if not isinstance(tree, dict):\n",
    "        return\n",
    "    feature_name, threshold = list(tree.keys())[0].split(\"<\")\n",
    "    gid_i  = gid(x, t, tree)\n",
    "    importance = gid_i * (len(x) / n_samples)\n",
    "    if feature_name in feature_results:\n",
    "        feature_results[feature_name].append(importance)\n",
    "    else:\n",
    "        feature_results[feature_name] = list([importance])\n",
    "\n",
    "    #recursing\n",
    "    subtree = list(tree.values())[0]\n",
    "    for expected_value, next_tree in subtree.items():\n",
    "        sub_x = x[(x[feature_name] < float(threshold)) == (expected_value == \"True\")]\n",
    "        sub_t = t[(x[feature_name] < float(threshold)) == (expected_value == \"True\")]\n",
    "        gini_importance_from_tree(sub_x, sub_t, next_tree, n_samples, feature_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          0.006983\n",
       "BMI          0.006818\n",
       "Income       0.003870\n",
       "HighChol     0.002311\n",
       "Veggies      0.001816\n",
       "Education    0.000982\n",
       "Sex          0.000378\n",
       "Fruits       0.000311\n",
       "Smoker       0.000305\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrials = 10\n",
    "ntrees = 25\n",
    "default = 0\n",
    "feature_results = {}\n",
    "for trial in range(ntrials):\n",
    "    X_train, X_test, t_train, t_test = train_test_split(dia_X, dia_t, test_size=0.3,random_state=trial)\n",
    "    trees = make_trees(X_train,t_train,ntrees=ntrees)\n",
    "    for tree in trees:\n",
    "        gini_importance_from_tree(dia_X_train, dia_t_train, tree, len(dia_X_train), feature_results)\n",
    "\n",
    "data = {key: sum(value) / len(value) for key, value in feature_results.items()}\n",
    "pd.Series(data).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense! This metrics intuitively seem important for estimating BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI          0.277710\n",
       "Age          0.210713\n",
       "Income       0.165448\n",
       "Education    0.110505\n",
       "Fruits       0.052029\n",
       "HighChol     0.046748\n",
       "Sex          0.045992\n",
       "Smoker       0.045799\n",
       "Veggies      0.045056\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ntrials = 10\n",
    "ntrees = 100\n",
    "default = 0\n",
    "sk_feature_results = {}\n",
    "for trial in range(ntrials):\n",
    "    X_train, X_test, t_train, t_test = train_test_split(dia_X, dia_t, test_size=0.3,random_state=trial)\n",
    "    classifier = RandomForestClassifier(n_estimators=ntrees, random_state=trial, min_samples_split=5, criterion=\"entropy\").fit(X_train,t_train)\n",
    "    for i in range(len(classifier.feature_names_in_)):\n",
    "        feature = classifier.feature_names_in_[i]\n",
    "        importance = classifier.feature_importances_[i]\n",
    "        if feature not in sk_feature_results:\n",
    "            sk_feature_results[feature] = [importance]\n",
    "        else:\n",
    "            sk_feature_results[feature].append(importance)\n",
    "\n",
    "pd.DataFrame(sk_feature_results).T.mean(axis=1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more is that it has very similar results to the built-in implementation! THe top 4 are all the same and all of the other values are only off by very small amounts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('Main10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40653dad27eb0252400c8e6bbf6cbe7329bda1d0b0ca7424b832f037e26face8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
